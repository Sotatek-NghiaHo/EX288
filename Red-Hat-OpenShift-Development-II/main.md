# Chapter 1.  Red Hat OpenShift Container Platform for Developers


![alt text](pic/1.png)
Control Plane

Kubernetes services
- etcd: the distributed key-value store, which Kubernetes uses to store configuration and state information about the containers and other resources inside the cluster.
- kube-apiserver: validates and configures cluster objects and provides the access point to the shared state of the cluster.
- kube-controller-manager: monitors etcd for changes and uses the Kubernetes API to apply changes to the cluster.
- kube-scheduler: selects the nodes where a workload must run.

## Red Hat OpenShift Concepts and Terminology

### Kubernetes Concepts

**Pods**  
A Pod is a collection of containers that share the same storage and network. Pods share the context by using Linux namespaces, cgroups, and other isolation technologies.

Each container in a pod usually contains applications that are more or less logically coupled.

**ReplicaSet**  
The ReplicaSet object indicates the number of pods that are available to attend a request. This object also ties all the pods replicas together so you can operate on them at the same time.

**Deployments**  
A Deployment contains the desired state of an application's pods and uses a ReplicaSet to achieve this desired state. Some changes in the application's state can be: creating pods, declaring a new state of pods, changing the number of pods, or rolling back to a previous Deployment revision.

**Service**  
A Kubernetes Service exposes a set of pods over a network. This abstraction allows internal or external clients of the application running on said pods to connect to them regardless of the actual state of the replicas or varying network IPs.

**Ingress**  
An Ingress exposes services inside the cluster to outside clients by using HTTP or HTTPS. A service ingress can also provide external URLs, load balancing, name-based virtual hosting, or SSL/TLS termination.

**Namespace**  
A Namespace can enable you to isolate resources, encapsulate objects under a unique name, and provide resource quotas.

**Custom Resource**  
Custom Resource (CR) allows extending the Kubernetes API. Custom resources represent entities other than the default ones in Kubernetes. Additionally, Custom resources interact with other cluster objects, regardless of whether those other objects are default or custom.

**Operator**  
An Operator is a custom Kubernetes controller that uses custom resources to deploy and manage applications. It takes high-level user configuration and acts to make the cluster match the desired state.

**Service Account**    
A Service Account is a special kind of account that does not correspond to an actual user, but it is used internally by cluster tools. It is useful for pods to connect to objects in the cluster, such as CI/CD pipelines, secrets, or external resources (outside of the namespace or the cluster).

**Storage Class**   
A Storage Class is a name that identifies a particular kind of storage defined by the cluster administrator. A storage class also defines its characteristics, such as backup policies, service level quality, or any other specification the administrator might choose.

**Persistent Volume**  
A Persistent Volume (PV), is a persistence storage unit offered by the cluster, independent of cluster nodes. This object holds information regarding the size, type, or ability to share storage.

**Persistent Volume Claim**  
Users claim the storage that a PV offers by using a Persistent Volume Claim (PVC). A PVC is a request to access a specific kind of storage of the required size. After acquiring the PVC, the storage is attached to the pods claiming it.

---
# Chapter 2.  Deploying Simple Applications

![alt text](pic/2.png)

![alt text](pic/3.png)

Deploying Applications by Using the Red Hat OpenShift Web Console
- Deploy an application by using a Git repository.
- Deploy an application by using an image from a container registry.

![alt text](pic/5.png)

![alt text](pic/6.png)


## Deploying Applications by Using the oc and odo CLIs



**Deploying Applications with the OpenShift CLI**   
For complex applications, you can use the oc apply command with the -f option. You provide a manifest file that defines the Kubernetes resources for your application.
```
[user@host ~]$ oc apply -f my-manifest.yaml
```
Deploying Applications with oc new-app

![alt text](pic/4.png)

To get a complete list of options and to see a list of examples, run the `oc new-app -h` command.

Example

![alt text](pic/8.png)

![alt text](pic/9.png)

You can delete resources that the oc new-app command creates by using a single oc delete command with the --selector option and the app label. The following command deletes the resources created by the previous oc new-app command:
```
[user@host ~]$ oc delete all --selector app=hello
```

Use the `-o` option to inspect resource definitions without creating resources.
```
[user@host ~]$ oc new-app \
-o yaml registry.example.com/mycontainerimage
apiVersion: v1
items:
- apiVersion: image.openshift.io/v1
  kind: ImageStream
  ...output omitted...
- apiVersion: build.openshift.io/v1
  kind: BuildConfig
  ...output omitted...
- apiVersion: apps/v1
  kind: Deployment
  ...output omitted...
- apiVersion: v1
  kind: Service
  ...output omitted...
kind: List
metadata: {}
```
**Exposing Applications Outside the Cluster.**  
Service resources are only accessible from within the cluster. To provide external access to your application, you can use the oc expose command.

The `oc expose` command creates a Route resource, a type of OpenShift-specific resource. This resource defines the port and protocol for access outside the cluster.

Syntax
```
oc expose [RESOURCE/NAME] [options]
```
Trong Ä‘Ã³:

- RESOURCE/NAME: loáº¡i resource vÃ  tÃªn (thÆ°á»ng lÃ  service/<service-name> hoáº·c deployment/<deploy-name>).
- [options]: cÃ¡c tÃ¹y chá»n Ä‘á»ƒ Ä‘á»‹nh nghÄ©a route hoáº·c service.


Má»™t sá»‘ option quan trá»ng

- `--name=<string>`
â†’ Äáº·t tÃªn cho resource má»›i Ä‘Æ°á»£c táº¡o (vÃ­ dá»¥: route).

- `--port=<port-name|number>`
â†’ Chá»‰ Ä‘á»‹nh cá»•ng tá»« Service mÃ  Route sáº½ expose (náº¿u Service cÃ³ nhiá»u port).

- `--target-port=<number>`
â†’ Chá»‰ Ä‘á»‹nh chÃ­nh xÃ¡c cá»•ng Ä‘Ã­ch trÃªn Pod container.

- `--hostname=<string>`
â†’ Äáº·t hostname (FQDN) cho Route. Náº¿u khÃ´ng cÃ³, OpenShift sáº½ generate.

- `--path=<string>`
â†’ Gáº¯n path cho Route (vÃ­ dá»¥ /api).

- `--type=<string>`
â†’ Loáº¡i service muá»‘n expose (ClusterIP, NodePort, LoadBalancer).

- `--generator=<string>`
â†’ Kiá»ƒu resource generator. Máº·c Ä‘á»‹nh khi expose Service lÃ  route/v1

CÃº phÃ¡p Ä‘áº§y Ä‘á»§ nháº¥t (hay dÃ¹ng):
```
oc expose service <service-name> \
  --name=<route-name> \
  --port=<service-port> \
  --hostname=<custom-host> \
  --path=<url-path>
```
ğŸ”¹ `--hostname=<custom-host>`

- DÃ¹ng khi báº¡n muá»‘n Route cÃ³ hostname cá»¥ thá»ƒ thay vÃ¬ hostname ngáº«u nhiÃªn OpenShift generate.
- TrÆ°á»ng há»£p dÃ¹ng:
  - Báº¡n muá»‘n public domain dá»… nhá»›, vÃ­ dá»¥:
```
oc expose service myservice --hostname=weather.apps.ocp.example.com
```
- Khi báº¡n Ä‘Ã£ cÃ³ DNS record trá» vá» OpenShift router (Ingress).
- Trong mÃ´i trÆ°á»ng production, hostname thÆ°á»ng Ä‘Æ°á»£c quy Ä‘á»‹nh trÆ°á»›c (VD: api.company.com, shop.company.com).

ğŸ‘‰ Náº¿u khÃ´ng set, OpenShift sáº½ tá»± táº¡o tÃªn dáº¡ng:
```
<route-name>-<project>.apps.<cluster-domain>
```
ğŸ”¹`--path=<url-path>`
- DÃ¹ng Ä‘á»ƒ thÃªm context path cho route.
- TrÆ°á»ng há»£p dÃ¹ng:
  - Khi báº¡n muá»‘n nhiá»u á»©ng dá»¥ng share chung 1 hostname, nhÆ°ng phÃ¢n biá»‡t báº±ng path.
VÃ­ dá»¥:
```
oc expose service backend --hostname=api.apps.ocp.example.com --path=/backend
oc expose service frontend --hostname=api.apps.ocp.example.com --path=/frontend
```
- Khi á»©ng dá»¥ng cá»§a báº¡n láº¯ng nghe trÃªn root /, nhÆ°ng báº¡n chá»‰ muá»‘n expose dÆ°á»›i má»™t nhÃ¡nh /app1 cháº³ng háº¡n.

ğŸ‘‰ Náº¿u khÃ´ng set, máº·c Ä‘á»‹nh path lÃ  `/` (root).

- `--hostname` â†’ dÃ¹ng khi báº¡n muá»‘n route cÃ³ domain cá»¥ thá»ƒ, nháº¥t lÃ  trong production (gáº¯n DNS chuáº©n).

- `--path` â†’ dÃ¹ng khi muá»‘n cháº¡y nhiá»u service/app dÆ°á»›i cÃ¹ng 1 domain nhÆ°ng phÃ¢n biá»‡t báº±ng Ä‘Æ°á»ng dáº«n.


OpenShift chá»n port nÃ o Ä‘á»ƒ expose khi dung `oc expose` command ? 
- oc expose service ... máº·c Ä‘á»‹nh láº¥y port tá»« Service.
- Náº¿u Service cÃ³ 1 port â†’ Route dÃ¹ng port Ä‘Ã³.
- Náº¿u Service cÃ³ nhiá»u port â†’ báº¡n pháº£i chá»‰ Ä‘á»‹nh --port.

*CÃ¡ch kiá»ƒm tra port service*
```
oc get service openshift-dev-deploy-cli-weather -o yaml
---
ports:
- name: 8080-tcp
  port: 8080
  targetPort: 8080

```
Service cÃ³ 8080 vÃ  8443 â†’ pháº£i chá»‰ Ä‘á»‹nh:
```
oc expose service myservice --port=8080
```

**Inner loop vs Outer loop**

![alt text](pic/7.png)

1. Inner loop vs Outer loop

- Inner loop: vÃ²ng láº·p ngáº¯n cá»§a dev â†’ code â†’ build â†’ test nhanh â†’ debug â†’ láº·p láº¡i.
  - ÄÃ¢y lÃ  pháº§n mÃ  odo há»— trá»£ máº¡nh nháº¥t (deploy code nhanh lÃªn cluster Ä‘á»ƒ test).

- Outer loop: vÃ²ng láº·p dÃ i hÆ¡n â†’ build artifact chÃ­nh thá»©c â†’ cháº¡y integration test, security test â†’ deploy vÃ o mÃ´i trÆ°á»ng prod/staging.
  - odo cÅ©ng cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a Ä‘Æ°á»£c qua devfile.yaml.

2. Devfile (devfile.yaml)

LÃ  file trung tÃ¢m, mÃ´ táº£:
- Components: container images, manifests, volumeâ€¦
- Commands: cÃ¡c bÆ°á»›c cáº§n cháº¡y (build, run, test, debug, deploy).
- Command groups: gom lá»‡nh theo nhÃ³m (`build, run, test, debug, deploy`).
Nhá» devfile, odo biáº¿t pháº£i lÃ m gÃ¬ khi báº¡n gÃµ:
- odo build
- odo run
- odo test
- odo debug
- odo deploy

Note: 
- Náº¿u muá»‘n odo <kind> cháº¡y máº·c Ä‘á»‹nh, báº¡n pháº£i báº­t isDefault: true.
- Náº¿u cÃ³ nhiá»u command cÃ¹ng kind thÃ¬ chá»‰ 1 Ä‘Æ°á»£c default, cÃ²n láº¡i pháº£i gá»i báº±ng --command <id>.

3. `odo init`
- Táº¡o file devfile.yaml ban Ä‘áº§u.
- odo sáº½ cá»‘ gáº¯ng Ä‘oÃ¡n runtime tá»« source code (vÃ­ dá»¥ tháº¥y package.json â†’ Node.js, tháº¥y requirements.txt â†’ Python).
- Náº¿u báº¡n khÃ´ng truyá»n options, nÃ³ sáº½ má»Ÿ interactive mode Ä‘á»ƒ báº¡n chá»n.
- NÃ³ cáº§n káº¿t ná»‘i tá»›i devfile registry (máº·c Ä‘á»‹nh: https://registry.devfile.io
) Ä‘á»ƒ láº¥y template phÃ¹ há»£p.

> Sau khi cÃ³ devfile.yaml, báº¡n cÃ³ thá»ƒ sá»­a Ä‘á»ƒ phÃ¹ há»£p vá»›i project.

4. Lá»‡nh `odo create project`
```
odo create project PROJECT_NAME
```
- Táº¡o má»™t OpenShift Project (namespace) má»›i trá»±c tiáº¿p tá»« odo.
- TÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i lá»‡nh: `oc new-project PROJECT_NAME`

The following devfile provides a simplified example for outer loop development with odo. The devfile adheres to the following requirements:

- The `Dockerfile` must exist in the same directory as the `devfile.yaml`.

- The `deploy.yaml` contains the Kubernetes resources for the application.

- The parent devfile must exist.

- The odo command must be able to access Podman and an authenticated image registry.

![alt text](pic/10.png)

Example deploy.yaml
```bash
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodejs-app
  labels:
    app: nodejs-app
spec:
...
---
apiVersion: v1
kind: Service
metadata:
  name: nodejs-app
  labels:
    app: nodejs-app
spec:
  selector:

...
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: nodejs-app
spec:
  to:

```
**Container Image Renaming with odo**  
*Váº¥n Ä‘á»*
- Trong devfile.yaml báº¡n cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a image component Ä‘á»ƒ build/push image.
- Náº¿u báº¡n viáº¿t tháº³ng image name Ä‘áº§y Ä‘á»§ (vÃ­ dá»¥: quay.io/myuser/nodejs-app:1.0), thÃ¬ devfile bá»‹ gáº¯n cháº·t vá»›i registry Ä‘Ã³ â†’ khÃ³ chia sáº» cho ngÆ°á»i khÃ¡c.
- VÃ¬ váº­y, odo há»— trá»£ image renaming Ä‘á»ƒ lÃ m devfile portable (dÃ¹ng láº¡i á»Ÿ nhiá»u cluster/registry khÃ¡c nhau).

*CÃ¡ch hoáº¡t Ä‘á»™ng*

1. Khai bÃ¡o `ImageRegistry`
Báº¡n set registry máº·c Ä‘á»‹nh Ä‘á»ƒ odo push image:
```
odo preference set ImageRegistry quay.io/myuser

# syntax
[user@host ~]$ odo preference set ImageRegistry REGISTRY_URL/NAMESPACE
```
â†’ Sau Ä‘Ã³ má»i image sáº½ Ä‘Æ°á»£c push vá» quay.io/myuser/....

2. DÃ¹ng imageName tÆ°Æ¡ng Ä‘á»‘i trong devfile  
Trong `devfile.yaml`:
```
components:
  - name: relative-image
    image:
      imageName: "my-relative-image"   # chá»‰ cÃ³ tÃªn, khÃ´ng cÃ³ registry
```

ğŸ‘‰ ÄÃ¢y gá»i lÃ  relative image name.

3. Khi build/push, odo sáº½ tá»± Ä‘á»•i tÃªn image thÃ nh:
```
<ImageRegistry>/<DevfileName>-<ImageName>:<UniqueId>
```
- ImageRegistry: giÃ¡ trá»‹ báº¡n set (quay.io/myuser)
- DevfileName: tÃªn devfile (vÃ­ dá»¥ nodejs-app)
- ImageName: pháº§n báº¡n Ä‘á»‹nh nghÄ©a (my-relative-image)
- UniqueId: giÃ¡ trá»‹ random Ä‘á»ƒ trÃ¡nh trÃ¹ng

ğŸ“ VÃ­ dá»¥ cá»¥ thá»ƒ

Devfile nodejs-app cÃ³:
```
components:
  - name: relative-image
    image:
      imageName: "my-relative-image"
```

Báº¡n set:
```
odo preference set ImageRegistry quay.io/nghia
```

Khi odo deploy, image thá»±c táº¿ Ä‘Æ°á»£c push sáº½ thÃ nh:
```
quay.io/nghia/nodejs-app-my-relative-image:abc123
```
âœ… Lá»£i Ã­ch

- Devfile khÃ´ng bá»‹ hard-code registry â†’ portable, dá»… chia sáº» cho team khÃ¡c.
- odo tá»± Ä‘á»™ng Ä‘á»•i tÃªn vÃ  push image Ä‘Ãºng registry báº¡n chá»‰ Ä‘á»‹nh.
- Báº¡n cÃ³ thá»ƒ kiá»ƒm tra:
  - Trong registry (quay.io/nghia/...)
  - Hoáº·c trong resource YAML mÃ  odo apply lÃªn cluster.

**Syntax há»¯u Ã­ch cá»§a oc new-app**
```bash
oc new-app <image>                  # Táº¡o tá»« image
oc new-app --image=<image>
oc new-app <image>~<git-repo>       # S2I build tá»« source code
oc new-app -f template.yaml         # DÃ¹ng template file
oc new-app --name=myapp             # Äáº·t tÃªn app
oc new-app <image> -e VAR=VALUE     # ThÃªm biáº¿n mÃ´i trÆ°á»ng
oc new-app <image> --as-deployment-config  # DÃ¹ng DeploymentConfig thay vÃ¬ Deployment
```

**Image mÃ  oc new-app dÃ¹ng tá»« Ä‘Ã¢u ra?**

![alt text](pic/11.png)

ğŸ”¹ 2. Váº­y podman build liÃªn quan gÃ¬?
- Náº¿u báº¡n tá»± build má»™t image báº±ng podman build trÃªn mÃ¡y local thÃ¬ image Ä‘Ã³ chá»‰ náº±m trong local host.
- Äá»ƒ OpenShift dÃ¹ng Ä‘Æ°á»£c, báº¡n pháº£i push image Ä‘Ã³ lÃªn má»™t registry (vÃ­ dá»¥: quay.io, docker.io, hoáº·c internal OpenShift registry image-registry.openshift-image-registry.svc:5000).

Sau Ä‘Ã³ báº¡n má»›i dÃ¹ng:
```
oc new-app <registry>/<namespace>/<image>:<tag>
```

Máº·c Ä‘á»‹nh `oc new-app` chá»‰ giÃºp báº¡n deploy nhanh Ä‘á»ƒ test, cÃ²n náº¿u muá»‘n tÃ¹y chá»‰nh chi tiáº¿t thÃ¬ cÃ³ vÃ i cÃ¡ch:

![alt text](pic/12.png)

**TÃ¹y chá»‰nh**

- TÃ¹y chá»‰nh ngay tá»« lá»‡nh `oc new-app`
```bash
# Example
oc scale deployment myapp --replicas=3
oc expose deployment myapp --port=8080 --target-port=8080
```
- Chá»‰nh sau khi resource Ä‘Æ°á»£c táº¡o
```bash
# Xuáº¥t YAML ra file Ä‘á»ƒ chá»‰nh:
oc get deployment myapp -o yaml > myapp-deploy.yaml

# -> Sá»­a YAML (replicas, resource limits, volume, env, liveness probeâ€¦)

# Apply láº¡i:
oc apply -f myapp-deploy.yaml
```
3. DÃ¹ng workflow hiá»‡n Ä‘áº¡i (recommended)  
Thay vÃ¬ `oc new-app` (quick & simple), báº¡n cÃ³ thá»ƒ:
- Viáº¿t sáºµn Deployment + Service YAML â†’ `oc apply -f`.
- Hoáº·c dÃ¹ng odo vá»›i devfile.yaml náº¿u phÃ¡t triá»ƒn app.
- Hoáº·c dÃ¹ng BuildConfig + ImageStream náº¿u muá»‘n workflow CI/CD theo kiá»ƒu OpenShift truyá»n thá»‘ng.

---
# Chapter 3.  Building and Publishing Container Images

Red Hat Universal Base Images
When defining custom container images, Red Hat recommends the use of Red Hat Universal Base Images (UBI) as the base container images for your applications. UBI images are certified, tested, and regularly maintained images that Red Hat provides at no cost.

UBI images also provide the following major benefits:

**Universal**  
UBI images are designed to be used as the base images for developing container-based applications.

**Robust**  
UBI images are based on Red Hat Enterprise Linux (RHEL). This brings characteristics such as stability and vulnerability management to your base container images.

**Standard**  
UBI images are compliant with the Open Container Initiative (OCI).

**Extensible**  
UBI images provide package managers and other tools for installing additional software.

**OpenShift-optimized**  
UBI images are tailored to work well on Red Hat OpenShift.

**Redistributable**  
The UBI End-User Licensing Agreement (EULA) permits free distribution of the applications that you build on top of UBI images.

Red Hat provides four types of UBI images, designed to cover most use cases.

Image type	|Image name	|Uses
---|---|---
Standard	|ubi|	For most applications and use cases
Init	|ubi-init|	For containers that run multiple systemd services
Minimal	|ubi-minimal	|Smaller image for applications that manage their own dependencies and depend on fewer OS components
Micro	|ubi-micro	|Smallest image for optimized memory-footprint use cases; for applications that use almost no OS components

Runtime UBI Images For Developers
Red Hat provides UBI images for the following runtime languages:
- OpenJDK
- Node.js
- Python
- PHP
- .NET
- Go
- Ruby
 
Optimize Containerfiles for OpenShift  
Format
```
registry.access.redhat.com/NAMESPACE/NAME[:TAG]
```
Example 
```
FROM registry.access.redhat.com/ubi10/nodejs-22-minimal:10.0
```
**Ensure That Your Containers Handle Interruption Signals**

ğŸ”¹ 1. CÆ¡ cháº¿ shutdown máº·c Ä‘á»‹nh

Khi báº¡n xÃ³a Pod hoáº·c rollout Deployment má»›i, OpenShift sáº½:
- Gá»­i tÃ­n hiá»‡u SIGTERM Ä‘áº¿n process PID 1 trong container.
- Container/app cá»§a báº¡n cÃ³ trÃ¡ch nhiá»‡m ngáº¯t káº¿t ná»‘i, Ä‘Ã³ng resource, lÆ°u dataâ€¦.
- Náº¿u trong thá»i gian terminationGracePeriodSeconds (máº·c Ä‘á»‹nh 30s) app khÃ´ng táº¯t â†’ OpenShift gá»­i SIGKILL (kill ngay láº­p tá»©c).

ğŸ‘‰ Do Ä‘Ã³, á»©ng dá»¥ng pháº£i biáº¿t cÃ¡ch handle SIGTERM Ä‘á»ƒ shutdown â€œÃªm Ä‘áº¹pâ€ (graceful shutdown).

ğŸ”¹ 2. TrÆ°á»ng há»£p á»©ng dá»¥ng khÃ´ng handle SIGTERM

VÃ­ dá»¥:
- Má»™t app Java cháº¡y báº±ng java -jar example.jar.
- Náº¿u báº¡n khÃ´ng trap SIGTERM, khi Pod bá»‹ kill â†’ Java process sáº½ táº¯t ngay â†’ cÃ³ thá»ƒ máº¥t data, chÆ°a commit transaction, connection bá»‹ cáº¯t Ä‘á»™t ngá»™t.

CÃ¡ch xá»­ lÃ½:
- Viáº¿t entrypoint script (nhÆ° vÃ­ dá»¥ trong bÃ i): trap tÃ­n hiá»‡u SIGTERM vÃ  forward cho app, rá»“i wait cho app shutdown.
```
trap graceful_shutdown SIGTERM
java -jar example.jar &
java_pid=$!
wait "$java_pid"
```

á» Ä‘Ã¢y:

- trap graceful_shutdown SIGTERM: khi nháº­n SIGTERM â†’ gá»i hÃ m graceful_shutdown.

- HÃ m nÃ y gá»­i SIGTERM Ä‘áº¿n process Java (kill -SIGTERM $java_pid) vÃ  Ä‘á»£i nÃ³ shutdown.

ğŸ”¹ 3. Khi app khÃ´ng sá»­a code Ä‘Æ°á»£c

Náº¿u á»©ng dá»¥ng khÃ´ng cÃ³ cÆ¡ cháº¿ nháº­n SIGTERM (hoáº·c báº¡n khÃ´ng thá»ƒ thay Ä‘á»•i entrypoint), báº¡n cÃ³ thá»ƒ dÃ¹ng Pod lifecycle hook:
```
lifecycle:
  preStop:
    httpGet:
      path: /shutdown
      port: 8080
```

- Khi Pod chuáº©n bá»‹ bá»‹ xÃ³a, kubelet sáº½ gá»i HTTP GET vÃ o /shutdown.

- á»¨ng dá»¥ng sáº½ nháº­n request nÃ y vÃ  thá»±c hiá»‡n cleanup (Ä‘Ã³ng káº¿t ná»‘i, flush cache, lÆ°u tráº¡ng thÃ¡i, v.v).

- Sau Ä‘Ã³ má»›i nháº­n SIGTERM Ä‘á»ƒ táº¯t háº³n.

ğŸ”¹ 4. Náº¿u app váº«n khÃ´ng táº¯t?

- Sau khi háº¿t thá»i gian terminationGracePeriodSeconds, kubelet/OpenShift gá»­i SIGKILL â†’ process bá»‹ kill ngay láº­p tá»©c.

- LÃºc nÃ y khÃ´ng cÃ³ cÆ¡ há»™i cleanup â†’ nguy cÆ¡ máº¥t dá»¯ liá»‡u hoáº·c lá»—i.

âœ… TÃ³m láº¡i

- OpenShift/K8s luÃ´n gá»­i SIGTERM trÆ°á»›c Ä‘á»ƒ cho app tá»± shutdown Ãªm Ä‘áº¹p.

- App nÃªn handle SIGTERM (qua entrypoint script).

- Náº¿u khÃ´ng thá»ƒ â†’ dÃ¹ng preStop hook Ä‘á»ƒ app cleanup trÆ°á»›c khi bá»‹ kill.

- Náº¿u app váº«n khÃ´ng shutdown ká»‹p â†’ cuá»‘i cÃ¹ng bá»‹ SIGKILL (force kill).

![alt text](pic/13.png)

**Reduce Image Size**

1. Giáº£m sá»‘ lÆ°á»£ng RUN
- Káº¿t há»£p nhiá»u lá»‡nh thÃ nh 1 RUN Ä‘á»ƒ giáº£m sá»‘ layer.

2. Giáº£m build context
- DÃ¹ng .dockerignore / .containerignore Ä‘á»ƒ loáº¡i bá» file/thÆ° má»¥c khÃ´ng cáº§n thiáº¿t.

3. Multistage build
- Stage Ä‘áº§u: build app báº±ng image Ä‘áº§y Ä‘á»§ (vÃ­ dá»¥: ubi9/nodejs-22).
- Stage cuá»‘i: copy artifact sang image minimal/runtime (ubi9/nodejs-22-minimal).
- â†’ Káº¿t quáº£: image nhá» gá»n, chá»‰ chá»©a runtime + app.

4. DÃ¹ng minimal image

- Node.js: nodejs-22-minimal.
- OpenJDK: ubi9/openjdk-21-runtime.

5. LABEL
- DÃ¹ng LABEL Ä‘á»ƒ khai bÃ¡o metadata.
- VÃ­ dá»¥: LABEL io.openshift.min-cpu 2 â†’ UI OpenShift cáº£nh bÃ¡o cáº§n Ã­t nháº¥t 2 CPU.

6. WORKDIR
- LuÃ´n dÃ¹ng WORKDIR vá»›i absolute path thay vÃ¬ nhiá»u láº§n cd trong RUN.
7. ENV vÃ  ARG
- DÃ¹ng ENV Ä‘á»ƒ cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n, version, PATHâ€¦
- DÃ¹ng ARG cho biáº¿n build-time â†’ táº¡o image tÃ¡i sá»­ dá»¥ng Ä‘Æ°á»£c.
8. VOLUME
- Khai bÃ¡o rÃµ VOLUME Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t mount dá»¯ liá»‡u.
- Náº¿u khÃ´ng mount, OpenShift sáº½ tá»± gáº¯n EmptyDir (ephemeral).

9. EXPOSE
- Chá»‰ expose port >1024 (khÃ´ng cáº§n quyá»n root).
- oc new-app sáº½ tá»± táº¡o Deployment + Service theo port Ä‘Æ°á»£c EXPOSE.
- Web console cÅ©ng nháº­n diá»‡n cÃ¡c port nÃ y Ä‘á»ƒ cáº¥u hÃ¬nh service.

ğŸ‘‰ TÃ³m gá»n láº¡i:
- Multistage + minimal UBI image â†’ giáº£m size.
- LABEL, ENV, VOLUME, EXPOSE â†’ giÃºp OpenShift hiá»ƒu rÃµ image, há»— trá»£ cáº¥u hÃ¬nh dá»… dÃ ng.
- WORKDIR vÃ  Ã­t RUN â†’ lÃ m Containerfile gá»n, dá»… maintain.

**Build and Push Images with Podman**  
You can use a tool such as Podman to build a container image locally and push the image to a container registry.

> Note
You can also use OpenShift to build your container images. The OpenShift build capabilities, such as Source-to-Image (S2I) and Docker builds, are covered later in this course. OpenShift also provides the OpenShift Builds framework, which is based on the Shipwright project.

Use the podman build command to create a container image from a Containerfile, as the following example shows:
```
[user@host ~]$ podman build CONTEXT_DIR -t IMAGE
```
The preceding command creates a local container image by using the Containerfile or Dockerfile at the CONTEXT_DIR directory. The produced image is called IMAGE. After building the container image locally, push the image to a container registry by using the podman push command.
```
[user@host ~]$ podman push IMAGE
```
> Note
You must be logged in to the registry to push images. You can log in with the podman login command.

After the image is published in the container registry, you can deploy the image by using any of the methods that Red Hat OpenShift provides, such as the web console, or the oc and odo CLIs.

## Guided Exercise: Building Container Images for Red Hat OpenShift


```bash
oc new-app \
--name greetings \
--image=registry.ocp4.example.com:8443/developer/images-ubi-greetings:1.0.0
```
File Containerfile
![alt text](pic/15.png)

3 error khi `oc new-app`  
![alt text](pic/14.png)

**Fix 1**  
Remove the USER instruction from the Containerfile. The file must look as follows:
```
FROM registry.ocp4.example.com:8443/ubi10/nodejs-22-minimal:10.0

ENV PORT=80
EXPOSE ${PORT}

ADD . $HOME

RUN npm ci --omit=dev && rm -rf .npm

CMD npm start
```

**Fix 2**  
Trong Linux (vÃ  cÅ©ng Ä‘Ãºng trong container), cÃ³ quy táº¯c:
- Port < 1024 = privileged ports â†’ chá»‰ process cháº¡y báº±ng root user má»›i bind Ä‘Æ°á»£c.
- Port â‰¥ 1024 = unprivileged ports â†’ báº¥t ká»³ non-root user nÃ o cÅ©ng bind Ä‘Æ°á»£c.

VÃ¬ sao lá»—i xáº£y ra?
- á»¨ng dá»¥ng cá»§a báº¡n cá»‘ gáº¯ng láº¯ng nghe trÃªn cá»•ng 80:
```
Error: listen EACCES: permission denied 0.0.0.0:80
```
- NhÆ°ng trong OpenShift, container cháº¡y vá»›i má»™t UID ngáº«u nhiÃªn, khÃ´ng pháº£i root.
- Do Ä‘Ã³, process Ä‘Ã³ khÃ´ng thá»ƒ má»Ÿ Ä‘Æ°á»£c cá»•ng 80 â†’ bÃ¡o lá»—i EACCES.

**Fix 3**  
Fix the permissions of the /var/cache directory. In the Containerfile, add a RUN instruction that runs as the root user and ensures that the group assigned to the /var/cache directory is the root group (0). Then, it should grant the root group the same permissions as the user that owns this directory. Finally, it should restore 1001 as the user ID that runs the application.
```bash
...omitted...
RUN npm ci --omit=dev && rm -rf .npm

USER root
RUN chgrp -R 0 /var/cache && \
    chmod -R g=u /var/cache
USER 1001

CMD npm start
```
-> rebuild image, run -rm , podman push -> oc new-app -> expose > get url

## Using External Registries in Red Hat OpenShift
There are many kinds of container registries:

**Public registries**  
Registries that allow anyone to consume container images directly from the internet without any authentication, such as Docker Hub, Quay.io, or the Red Hat Registry.

**Private registries**  
Registries that are available only to selected consumers and usually require authentication. The Red Hat terms-based registry is an example of a private container registry.

**Enterprise registries**  
Registries that your organization manages. Such registries are usually available only to the organization's employees.

**OpenShift internal registries**  
A registry server managed internally by an OpenShift cluster to store container images.

These kinds of registries are not mutually exclusive: a registry can be, at the same time, both public and private.

**Creating Registry Credentials in OpenShift**  
1. You can use the oc create command to create a secret, for example:
```
[user@host ~]$ oc create secret generic example-secret \
--from-literal=user=developer --namespace=example-ns
secret/example-secret created
```
2. You can use the OpenShift console to create secrets. In the Developer perspective, click Secrets. Select a project, click Create, and then select the secret type that you want to create.

![alt text](pic/17.png)

3. Kubernetes provides the docker-registry secret type to store credentials for authentication with the container registry.

```bash
[user@host ~]$ oc create secret docker-registry SECRET_NAME \
--docker-server REGISTRY_URL \
--docker-username USER \
--docker-password PASSWORD \
--docker-email=EMAIL
secret/SECRET_NAME created
```
4. Táº¡o trá»±c tiáº¿p trong Web Console (GUI)
- VÃ o Workloads â†’ Secrets â†’ Create â†’ Image pull secret.
- Nháº­p server URL, user, password, email.

![alt text](pic/16.png)

You can also create the secret from existing credentials. For example, if you logged in to the private registry with Podman, then you have existing credentials in the `${XDG_RUNTIME_DIR}/containers/auth.json` file. Because the auth.json file uses the same structure as the .dockerconfigjson file, you can create the secret by using the `auth.json` file.
```
[user@host ~]$ oc create secret generic SECRET_NAME \
--from-file .dockerconfigjson=${XDG_RUNTIME_DIR}/containers/auth.json \
--type kubernetes.io/dockerconfigjson
```
You can also upload the auth.json file in the OpenShift console when creating the secret.

**Configuring OpenShift to Use the Registry Credentials**  
You can configure OpenShift to use custom credentials by using the `spec.imagePullSecrets` Pod property, for example:
```
apiVersion: v1
kind: Pod
metadata:
  name: example-pod
spec:
  containers:
  - name: example-container
    image: REGISTRY_URL
  imagePullSecrets:
  - name: SECRET_NAME
```
Consequently, you can use the property for controllers, such as the Deployment objects:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: example-container
          image: REGISTRY_URL
      imagePullSecrets:
        - name: SECRET_NAME
```

**Linking Registry Credentials to Service Accounts**

Instead of manually assigning the credentials to pods, you can configure OpenShift to assign the credentials to pods automatically by using service accounts. A service account provides an identity for pods. Pods use the default service account unless you configure a different service account.

Use the oc secrets link command to connect a secret with a service account, for example:
```
[user@host ~]$ oc secrets link --for=pull default SECRET_NAME
no output expected
```
Hoáº·c cho build config:
```
oc secrets link builder my-registry-secret --for=pull
```
The preceding command creates a new entry in the service account imagePullSecrets field:
```
apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
imagePullSecrets:
- name: SECRET_NAME
```
When you create a pod that uses the default service account, it inherits the imagePullSecrets field without you explicitly specifying the field in the pod definition.

This means that every pod that uses the default service account is authorized with the registry credentials in your secret.  
Giai thich:
- Báº¡n Ä‘Ã£ táº¡o secret trÆ°á»›c Ä‘Ã³ (chá»©a thÃ´ng tin registry account).
- CÃ¢u lá»‡nh nÃ y sáº½ gáº¯n secret vÃ o ServiceAccount default cá»§a project hiá»‡n táº¡i.
- Ká»ƒ tá»« lÃºc Ä‘Ã³, báº¥t ká»³ Pod nÃ o trong project cháº¡y vá»›i SA default sáº½ tá»± Ä‘á»™ng dÃ¹ng secret nÃ y khi pull image tá»« registry private.

-> 2 cÃ¡ch chÃ­nh Ä‘á»ƒ sá»­ dá»¥ng secret Ä‘Ã³ trong OpenShift/Kubernetes:
- CÃ¡ch 1: Khai bÃ¡o trá»±c tiáº¿p trong workload (spec.imagePullSecrets)
- CÃ¡ch 2: Gáº¯n secret vÃ o ServiceAccount (oc secrets link)

NguyÃªn táº¯c
- Secret lÃ  resource â€œnamespace-scopedâ€ â†’ chá»‰ tá»“n táº¡i trong project (namespace) nÃ o nÃ³ Ä‘Æ°á»£c táº¡o.
- Do Ä‘Ã³:
  - Secret trong project A khÃ´ng thá»ƒ dÃ¹ng trá»±c tiáº¿p á»Ÿ project B.
  - Náº¿u project B cÅ©ng cáº§n dÃ¹ng â†’ báº¡n pháº£i táº¡o láº¡i secret trong project B (cÃ³ thá»ƒ cÃ¹ng thÃ´ng tin).

CÃ³ thá»ƒ dung ServiceAccount khÃ¡c thay vÃ¬ default
```
oc secrets link custom-sa my-registry-secret --for=pull

# 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      serviceAccountName: custom-sa   # dÃ¹ng SA nÃ y thay vÃ¬ default
      containers:
      - name: myapp
        image: quay.io/myuser/private-app:1.0

```

*Search for the failed event messages that the application emits.*
```
[student@workstation ~]$ oc get event --field-selector type=Warning \
-o jsonpath='{range .items[]}{.message}{"\n"}{end}'
Failed to pull image "registry.ocp4.example.com:8443/redhattraining/hello-world-nginx:latest": ... invalid username/password: unauthorized: ...
```

![alt text](pic/18.png)

Docs: https://docs.redhat.com/en/documentation/openshift_container_platform/4.8/html/authentication_and_authorization/understanding-and-creating-service-accounts


Fix error  "Robot Accounts"

![alt text](pic/19.png)

7. Delete the robot account from the internal registry.

On the Robot Accounts page, click the gear icon of the developer+ocprobot account, and then click Delete Robot developer+ocprobot. Click Ok to complete the process.

## 3.5 Creating Image Streams
Image streams have the following benefits:
- They provide a level of indirection to the container image that OpenShift runs.
- They allow for rolling back to a previous container version without updating the image registry.
- They enable build and deployment automations when an image stream tag gets updated.
- They enable the caching of images from external image registries.
- You can use role-based access control (RBAC) on the image stream object to secure access to container images.

Váº¥n Ä‘á»: má»—i láº§n Ä‘á»•i image â†’ báº¡n pháº£i can thiá»‡p thá»§ cÃ´ng.
Trong khi Ä‘Ã³, náº¿u dÃ¹ng ImageStream + ImageChange trigger thÃ¬ chá»‰ cáº§n cáº­p nháº­t oc tag hoáº·c build má»›i   
â†’ OpenShift tá»± rollout cho báº¡n.


![alt text](pic/20.png)

![alt text](pic/21.png)

**Managing Image Streams and Tags**

For example, the following command imports a my-app-stream container image from an external container registry and periodically checks for updates:
```
[user@host ~]$ oc import-image myimagestream --confirm --scheduled=true \
--from example.com/example-repo/my-app-image
```
To create one image stream tag resource for each container image tag that exists in the source registry server, add the --all option to the oc import-image command. The following command creates or updates all image stream tags for new tags on the source registry server:
```
[user@host ~]$ oc import-image myimagestream --confirm --all \
--from registry/myorg/myimage
```
Running the oc import-image command on an existing image stream updates one of its current image stream tags to the current image IDs on the source registry server, such as in the following command:
```
[user@host ~]$ oc import-image myimagestream[:tag]
```
Exert finer control over an image stream tag by using the oc tag command. This enables you to associate an image stream tag with the following:
- A different registry than the one in its image stream
- A different container image name and tag
- An image ID that might not be the one currently associated with the image tag on the registry server
- An alias for the image stream tag

For example, to update the latest image stream tag to point to a different tag you can run the following command:
```
[user@host ~]$ oc tag myimagestream:tag myimagestream:latest
```
**Creating Image Streams From Private Registries**  
The following example commands use Podman to log in to a private registry, create a secret to store the access token, and create an image stream that points to the private registry:
```
[user@host ~]$ podman login -u myuser registry.example.com
[user@host ~]$ oc create secret generic regtoken \
--from-file .dockerconfigjson=${XDG_RUNTIME_DIR}/containers/auth.json \
--type kubernetes.io/dockerconfigjson
[user@host ~]$ oc import-image myimagestream --confirm \
--from registry.example.com/myorg/myimage
```
After you create an image stream, you can use it to deploy an application by using the oc new-app command and by using the `-i` option to specify the image stream.

By default, an image stream resource is only available to create applications or builds in the same project.

**Using Image Streams with Kubernetes Resources**

**Sharing an Image Stream Between Multiple Projects**

ğŸ“Œ 1. Táº¡o vÃ  quáº£n lÃ½ ImageStream

Táº¡o IS rá»—ng:
```
oc create is myapp
```

Xem danh sÃ¡ch IS trong project:
```
oc get is
```

Xem chi tiáº¿t 1 IS:
```
oc describe is myapp
```

XoÃ¡ IS:
```
oc delete is myapp
```
ğŸ“Œ 2. Import image tá»« registry vÃ o IS

Import má»™t image cá»¥ thá»ƒ:
```
oc import-image myapp:1.0 --from=quay.io/example/myapp:1.0 --confirm
```

Import táº¥t cáº£ tag tá»« má»™t repo:
```
oc import-image myapp --from=quay.io/example/myapp --all --confirm
```

Import cÃ³ lá»‹ch trÃ¬nh (scheduled):
```
oc import-image myapp --from=quay.io/example/myapp --confirm --scheduled=true
```

Cáº­p nháº­t tag hiá»‡n cÃ³:
```
oc import-image myapp:latest
```
ğŸ“Œ 3. Quáº£n lÃ½ tag cá»§a IS

Táº¡o alias giá»¯a cÃ¡c tag:
```
oc tag myapp:1.0 myapp:latest
```

Copy tá»« IS khÃ¡c:
```
oc tag otheris:2.0 myapp:dev
```

GÃ¡n IS tag vá»›i image ngoÃ i registry:
```
oc tag quay.io/example/myapp:3.0 myapp:stable
```
ğŸ“Œ 4. LiÃªn quan tá»›i á»©ng dá»¥ng

DÃ¹ng IS Ä‘á»ƒ táº¡o app (DeploymentConfig):
```
oc new-app -i myapp:latest --name=myapp
```

Xem Pod nÃ o Ä‘ang dÃ¹ng IS:
```
oc describe is myapp
```

(pháº§n â€œImage Stream Tag Historyâ€ sáº½ show DeploymentConfig, Builds nÃ o Ä‘ang dÃ¹ng tag Ä‘Ã³).

ğŸ“Œ 5. BuildConfig vÃ  IS

Build output vá» IS:
```
oc new-build --binary --name=myapp --to=myapp:1.0
oc start-build myapp --from-dir=. --follow
```

ğŸ‘‰ TÃ³m gá»n:

- oc create is / oc delete is â†’ quáº£n lÃ½ ImageStream.
- oc import-image â†’ kÃ©o image tá»« registry vÃ o IS.
- oc tag â†’ quáº£n lÃ½ tag trong IS.
- oc new-app -i â†’ deploy app tá»« IS (DeploymentConfig + trigger).
- oc describe is â†’ theo dÃµi ai Ä‘ang dÃ¹ng IS.

---
# Chapter 4.  Managing Red Hat OpenShift Builds
ğŸ”¹ OpenShift Build Process (CÃ¡ch OpenShift build image)
1. CÃ¡c thÃ nh pháº§n chÃ­nh khi build

- Trigger â†’ cÃ¡i gÃ¬ khá»Ÿi cháº¡y build (git commit, webhook, thay Ä‘á»•i image).
- Strategy â†’ build theo cÃ¡ch nÃ o (Source-to-Image (S2I), Dockerfile/Buildah, Custom).
- Input sources â†’ code, binary, hoáº·c Dockerfile.
- Output â†’ image Ä‘Æ°á»£c push vÃ o registry.

ğŸ‘‰ OpenShift cung cáº¥p 2 cÃ¡ch build chÃ­nh:

- BuildConfig (cá»• Ä‘iá»ƒn): tÃ i nguyÃªn gá»‘c cá»§a OpenShift, khai bÃ¡o YAML rá»“i build.
- Shipwright (má»›i, Kubernetes-native): dá»±a trÃªn upstream project, linh hoáº¡t, há»— trá»£ nhiá»u tool (S2I, Buildah, Buildpacks).

2. Shipwright (Builds for OpenShift)
- Kubernetes-native: dÃ¹ng CRD nhÆ° cÃ¡c resource khÃ¡c.
- Linh hoáº¡t: há»— trá»£ nhiá»u chiáº¿n lÆ°á»£c build.
- Dá»… dÃ¹ng: cÃ³ CLI shp, tÃ­ch há»£p trong Web Console.

CÃ¡c CR quan trá»ng:
- Build: Ä‘á»‹nh nghÄ©a cÃ¡i gÃ¬ cáº§n build (nguá»“n code, chiáº¿n lÆ°á»£c, output image).
- BuildStrategy / ClusterBuildStrategy: mÃ´ táº£ cÃ¡ch build (vÃ­ dá»¥ S2I, Buildah, Buildpacks).
- BuildRun: khi cháº¡y build, sáº½ táº¡o ra má»™t Pod thá»±c hiá»‡n build.

3. VÃ­ dá»¥ vá»›i Buildah

Build resource (khai bÃ¡o build):
```bash
apiVersion: shipwright.io/v1beta1
kind: Build
metadata:
  name: buildah-golang-build
spec:
  source:                 # code nguá»“n
    type: Git
    git:
      url: https://github.com/shipwright-io/sample-go
    contextDir: docker-build
  strategy:               # chiáº¿n lÆ°á»£c build
    name: buildah
    kind: ClusterBuildStrategy
  paramValues:            # tham sá»‘ build
  - name: dockerfile
    value: Dockerfile
  output:                 # image output
    image: image-registry.openshift-image-registry.svc:5000/buildah-example/sample-go-app
```

ğŸ‘‰ Giáº£i thÃ­ch:
- source: láº¥y code tá»« GitHub.
- strategy: dÃ¹ng Buildah.
- paramValues: chá»‰ ra Dockerfile.
- output: image sáº½ Ä‘Æ°á»£c push vÃ o internal registry.

BuildRun resource (cháº¡y build):
```bash
apiVersion: shipwright.io/v1beta1
kind: BuildRun
metadata:
  name: buildah-golang-buildrun
spec:
  build:
    name: buildah-golang-build
```

ğŸ‘‰ BuildRun chá»‰ cáº§n tham chiáº¿u Ä‘áº¿n Build Ä‘Ã£ Ä‘á»‹nh nghÄ©a â†’ Shipwright táº¡o Pod Ä‘á»ƒ build.

4. CLI shp (thay cho YAML dÃ i dÃ²ng)

Táº¡o Build:
```bash
shp build create buildah-golang-build \
  --source-url="https://github.com/redhat-openshift-builds/samples" \
  --source-context-dir="buildah-build" \
  --strategy-name="buildah" \
  --dockerfile="Dockerfile" \
  --output-image="image-registry.openshift-image-registry.svc:5000/buildah-example/go-app"
```

Cháº¡y build:
```
shp build run buildah-golang-build --follow
```
âœ… TÃ³m táº¯t 

- BuildConfig: kiá»ƒu cÅ©, thuáº§n OpenShift.
- Shipwright (Builds for OpenShift): kiá»ƒu má»›i, Kubernetes-native, linh hoáº¡t hÆ¡n.
- Build = Ä‘á»‹nh nghÄ©a build, BuildStrategy = cÃ¡ch build, BuildRun = cháº¡y build.
- VÃ­ dá»¥: láº¥y code tá»« GitHub â†’ dÃ¹ng Buildah vá»›i Dockerfile â†’ output thÃ nh image trong registry.

**Builds using BuildConfig**

![alt text](pic/22.png)

**The S2I Build Workflow**

![alt text](pic/23.png)

âœ… TÃ³m táº¯t

- Builder image: image Ä‘áº·c biá»‡t Ä‘á»ƒ build app tá»« source â†’ output image.
- S2I scripts: assemble (cÃ¡ch build), run (cÃ¡ch cháº¡y).
- CÃ³ 2 cÃ¡ch dÃ¹ng:
  - Táº¡o builder image chá»©a sáºµn script.
  - Override báº±ng .s2i/bin/ trong repo â†’ nhanh hÆ¡n, khÃ´ng cáº§n rebuild builder image.

## 4.3 Managing Application Builds
Create a Build Configuration
There are two ways to create a build configuration using the oc CLI: `oc new-app` and `oc new-build`.




## 4.5 Triggering Builds

## 4.7 Customizing an Existing S2I Base Image

---
# Chapter 5.  Managing Red Hat OpenShift Deployments

1. KhÃ¡i niá»‡m chung
- Deployment trong OpenShift tá»± Ä‘á»™ng hÃ³a quÃ¡ trÃ¬nh cáº­p nháº­t á»©ng dá»¥ng.
- Má»¥c tiÃªu: giáº£m downtime, tÄƒng tÃ­nh á»•n Ä‘á»‹nh, há»— trá»£ phÃ¡t hÃ nh liÃªn tá»¥c.
- YÃªu cáº§u app cáº§n tuÃ¢n thá»§ best practices:
  - Xá»­ lÃ½ tÃ­n hiá»‡u SIGTERM Ä‘á»ƒ táº¯t graceful.
  - Health/Readiness probe Ä‘á»ƒ router chá»‰ gá»­i request Ä‘áº¿n pod khá»e.

2. Deployment Resource
- LÃ  Kubernetes-native (dÃ¹ng ReplicaSet).
- TÃ­nh nÄƒng: rollout theo config, scale, pause/resume rollout.
- DeploymentConfig (kiá»ƒu cÅ©) Ä‘Ã£ bá»‹ deprecated.

3. Chiáº¿n lÆ°á»£c Deployment
- CÃ³ 2 nhÃ³m:  
a. Dá»±a trÃªn Deployment Resource
- Rolling (RollingUpdate)
  - Máº·c Ä‘á»‹nh.
  - Tá»«ng bÆ°á»›c thay pod cÅ© báº±ng pod má»›i.
  - KhÃ´ng downtime.
  - DÃ¹ng khi app cháº¡y song song Ä‘Æ°á»£c nhiá»u version.
- Recreate
  - XÃ³a toÃ n bá»™ pod cÅ© â†’ cháº¡y pod má»›i.
  - CÃ³ downtime.
  - DÃ¹ng khi app khÃ´ng há»— trá»£ cháº¡y song song, hoáº·c sá»­ dá»¥ng PVC vá»›i RWO / RWOP.

b. Dá»±a trÃªn Router

1. Blue-Green
  - 2 mÃ´i trÆ°á»ng (Blue â€“ má»›i, Green â€“ cÅ©) cháº¡y song song.
  - Route trá» vÃ o version nÃ o thÃ¬ user dÃ¹ng version Ä‘Ã³.
  - Dá»… rollback.

2. A/B
- Route chia traffic theo tá»· lá»‡ (vÃ­ dá»¥ 10% Blue, 90% Green).
- DÃ¹ng Ä‘á»ƒ test dáº§n, tÄƒng traffic tá»« tá»« cho version má»›i.

## 5.3 Managing Application Deployments
`oc rollout`  
The oc rollout command provides the cancel, pause, undo, retry, and more options for your deployments.
1. Xem tráº¡ng thÃ¡i rollout
```
oc rollout status deployment example-deployment
```
- DÃ¹ng Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh triá»ƒn khai (xem pod cÅ© Ä‘Ã£ xoÃ¡ chÆ°a, pod má»›i Ä‘Ã£ cháº¡y chÆ°a).
- Káº¿t quáº£ vÃ­ dá»¥:
  - Waiting for deployment ... rollout to finish... â†’ Ä‘ang triá»ƒn khai.
  - successfully rolled out â†’ triá»ƒn khai thÃ nh cÃ´ng.

2. Rollback (quay láº¡i version trÆ°á»›c)
```
oc rollout undo deployment example-deployment
```
- Náº¿u version má»›i bá»‹ lá»—i, quay láº¡i version cÅ© ngay.
- Giá»‘ng nhÆ° Ctrl+Z cho Deployment ğŸ˜„.

3. Pause (táº¡m dá»«ng rollout)
```
oc rollout pause deployment example-deployment
```
- DÃ¹ng khi báº¡n muá»‘n táº¡m dá»«ng triá»ƒn khai tá»± Ä‘á»™ng (vÃ­ dá»¥: báº¡n Ä‘ang sá»­a nhiá»u config).
- LÃºc nÃ y thay Ä‘á»•i khÃ´ng Ã¡p dá»¥ng ngay.

4. Resume (tiáº¿p tá»¥c rollout)
```
oc rollout resume deployment example-deployment
```
- Sau khi chá»‰nh sá»­a xong, dÃ¹ng lá»‡nh nÃ y Ä‘á»ƒ cho rollout tiáº¿p tá»¥c.

`oc scale`  
The oc scale command scales the number of replicas for a given deployment:
```
[user@host ~]$ oc scale deployment example-deployment --replicas=3
deployment.apps/example-deployment scaled
```

**Create Secrets and Configuration Maps**
Similarly to secrets, you can create configuration maps by using the oc create command:
```
[user@host ~]$ oc create configmap example-cm \
--from-literal key1=value1 \
--from-literal key2=value2
configmap/example-cm created
```
The previous command creates the following YAML object:
```
kind: ConfigMap
metadata:
    name: example-cm
apiVersion: v1
data:
    key1: value1
    key2: value2
```
You can also create configuration maps from a file or a directory:
```
[user@host ~]$ oc create configmap example-cm \
--from-file=redis.conf
configmap/example-cm created
```
The preceding example creates a configuration map with the redis.conf key and the contents of the file as its value. Developers might also rename the key, such as:
```bash
[user@host ~]$ oc create configmap example-cm \
--from-file=primary=/etc/redis/redis.conf \
--from-file=replica=replica-redis.conf
configmap/example-cm created
```
The preceding example creates a configuration map with the following keys:
- The primary key with the contents of the local /etc/redis/redis.conf file.
- The replica key with the contents of the local ./replica-redis.conf file.

Finally, similarly to secrets, you can use the OpenShift web console to create configuration maps. In the developer perspective, click ConfigMaps, select your project, and click Create ConfigMap.

**Manage Secrets and Configuration Maps**  
*View resources*  
To view details of a resource, use the oc get command:
```
[user@host ~]$ oc get secret mysecret -o yaml
...output omitted...
```
The -o yaml parameter displays the resource in the YAML language  
*Edit resources*  
To edit a resource, use the oc edit command:
```
[user@host ~]$ oc edit configmap my-cm
...output omitted...
```
Alternatively, you can edit resources in the OpenShift web console.  

*Patch resources*  
Patching a resource refers to updating the resource by applying a set of changes rather than interactively. This is useful, for example, in scripts. Use the oc patch command to patch a resource, for example:
```
[user@host ~]$ oc patch configmap/my-cm \
--patch '{"data":{"key1":"newvalue1"}}'
configmap/my-cm patched
```
The preceding command changes the .data.key1 key to the newvalue1 value.

The preceding commands work on any OpenShift resource. However, to edit secrets, you must use values in base64 encoding. You can encode any string by using the base64 command, for example:
```bash
[user@host ~]$ echo -n 'hunter3' | base64
aHVudGVyMw==

# decode
[user@host ~]$ echo -n 'aHVudGVyMw==' | base64 --decode
hunter3
```
*Inject Data to Pods*  
You can mount configuration maps and secrets as data volumes or expose the data as environment variables, inside an application container.

CÃ³ 2 cÃ¡ch Ä‘á»ƒ Ä‘Æ°a dá»¯ liá»‡u tá»« ConfigMap hoáº·c Secret vÃ o trong Pod:
- Inject thÃ nh biáº¿n mÃ´i trÆ°á»ng (env).
- Mount thÃ nh file trong container.

1. Inject ConfigMap/Secret thÃ nh Environment Variables

VÃ­ dá»¥ lá»‡nh:
```
oc set env deployment my-deployment --from configmap/my-cm
```
- Ã nghÄ©a: Láº¥y táº¥t cáº£ key/value trong ConfigMap my-cm â†’ inject vÃ o Deployment my-deployment â†’ thÃ nh biáº¿n mÃ´i trÆ°á»ng trong container.
- Káº¿t quáº£ trong pod:
```
env:
  - name: KEY1
    valueFrom:
      configMapKeyRef:
        key: key1
        name: my-cm
```
- DÃ¹ng khi app Ä‘á»c config tá»« ENV.

2. Mount ConfigMap/Secret thÃ nh Volume (file trong container)

VÃ­ dá»¥ lá»‡nh:
```
oc set volume deployment my-deployment --add \
-t secret -m /mnt/secret \
--name myvol --secret-name my-secret
```

Ã nghÄ©a: Mount Secret my-secret vÃ o Deployment my-deployment, gáº¯n táº¡i /mnt/secret.

Káº¿t quáº£ trong pod:
```
volumeMounts:
- mountPath: /mnt/secret
  name: myvol
volumes:
- name: myvol
  secret:
    secretName: my-secret
```

DÃ¹ng khi app cáº§n file (vÃ­ dá»¥: username.txt, password.txt, TLS certâ€¦).

3. LÆ°u Ã½ quan trá»ng
- ConfigMap/Secret chá»‰ dÃ¹ng trong cÃ¹ng namespace (khÃ´ng share giá»¯a project).
- Náº¿u báº¡n cáº­p nháº­t ConfigMap/Secret, pod Ä‘ang cháº¡y khÃ´ng tá»± Ä‘á»™ng nháº­n giÃ¡ trá»‹ má»›i.
  - Báº¡n pháº£i xÃ³a pod hoáº·c rollout láº¡i deployment Ä‘á»ƒ pod má»›i nháº­n giÃ¡ trá»‹ update. Update config thÃ¬ cáº§n tÃ¡i táº¡o pod Ä‘á»ƒ Ã¡p dá»¥ng giÃ¡ trá»‹ má»›i.

1. Service Account (SA) lÃ  gÃ¬?
- LÃ  identity (danh tÃ­nh) cho á»©ng dá»¥ng trong OpenShift.
- CÃ³ thá»ƒ gáº¯n quyá»n RBAC, secrets, SCC (Security Context Constraints)â€¦ vÃ o SA.
- Máº·c Ä‘á»‹nh, má»i pod dÃ¹ng default service account trong namespace.
- Má»—i SA cÃ³ má»™t JWT token Ä‘Æ°á»£c mount vÃ o pod táº¡i:
```
/var/run/secrets/kubernetes.io/serviceaccount
```

â†’ Pod cÃ³ thá»ƒ dÃ¹ng token nÃ y Ä‘á»ƒ gá»i OpenShift API.

2. Táº¡o vÃ  gÃ¡n Service Account
- Táº¡o SA:
```
oc create serviceaccount my-sa
```
- GÃ¡n SA cho deployment:
```
oc set serviceaccount deployment nginx-deployment my-sa
```
Káº¿t quáº£: deployment nginx-deployment sáº½ cháº¡y pod vá»›i SA my-sa.

ğŸ‘‰ DÃ¹ng khi app cáº§n quyá»n Ä‘áº·c biá»‡t (vÃ­ dá»¥: CI/CD pipeline hoáº·c operator gá»i API OpenShift).

3. Security Context & SCC
a. Security Context
- XÃ¡c Ä‘á»‹nh quyá»n, UID, GID, capabilities mÃ  container Ä‘Æ°á»£c phÃ©p.
- VÃ­ dá»¥: cháº¡y non-root, cáº¥m privilege escalation.

b. SCC (Security Context Constraints)
- LÃ  policy báº£o máº­t riÃªng cá»§a OpenShift.
- Tá»± Ä‘á»™ng Ã¡p dá»¥ng security context cho pod.
- Máº·c Ä‘á»‹nh, pod thÆ°á»ng dÃ¹ng SCC restricted-v2.

ğŸ‘‰ Admin cÃ³ thá»ƒ gáº¯n SCC vÃ o SA â†’ Pod nÃ o cháº¡y vá»›i SA Ä‘Ã³ sáº½ Ä‘Æ°á»£c Ã¡p dá»¥ng SCC tÆ°Æ¡ng á»©ng.

4. VÃ­ dá»¥ Deployment vá»›i Security Context
```
securityContext:
  runAsNonRoot: true
  allowPrivilegeEscalation: false
  seccompProfile:
    type: RuntimeDefault
  capabilities:
    drop:
    - ALL
```
- runAsNonRoot: true â†’ cáº¥m cháº¡y user root.
- allowPrivilegeEscalation: false â†’ khÃ´ng cho container tÄƒng quyá»n.
- capabilities.drop: ALL â†’ bá» háº¿t Linux capabilities.
- seccompProfile: RuntimeDefault â†’ dÃ¹ng cáº¥u hÃ¬nh báº£o máº­t máº·c Ä‘á»‹nh cá»§a runtime.

5. LÆ°u Ã½ quan trá»ng
- SA + SCC quyáº¿t Ä‘á»‹nh pod Ä‘Æ°á»£c phÃ©p lÃ m gÃ¬.
- Náº¿u khÃ´ng chá»‰ Ä‘á»‹nh â†’ OpenShift sáº½ Ã¡p dá»¥ng máº·c Ä‘á»‹nh (restricted-v2).
- Äá»ƒ cháº¡y pod Ä‘áº·c biá»‡t (vÃ­ dá»¥ cáº§n quyá»n hostPath, privileged) â†’ cáº§n gÃ¡n SCC phÃ¹ há»£p cho SA.

## 5.5 Deploying Stateful Applications

**Persistent Volumes and Persistent Volume Claims**  
*Persistent Volumes*  
![alt text](pic/24.png)

*Persistent Volume Claims*  
Persistent volume claims (PVCs) represent a request for a persistent volume. These requests can include requirements for the PV, such as the following attributes:
- Amount of storage
- Label selector
- Volume mode
- Access mode
- Storage class

![alt text](pic/25.png)

**Static and Dynamic Provisioning**

1. Static Provisioning
- Admin táº¡o PV thá»§ cÃ´ng trÆ°á»›c â†’ Developer chá»‰ táº¡o PVC Ä‘á»ƒ claim vÃ o PV Ä‘Ã£ cÃ³.
- NhÆ°á»£c Ä‘iá»ƒm:
  - Tá»‘n cÃ´ng quáº£n lÃ½ (Admin pháº£i Ä‘oÃ¡n trÆ°á»›c dung lÆ°á»£ng).
  - Dá»… lÃ£ng phÃ­ náº¿u PV khÃ´ng Ä‘Æ°á»£c dÃ¹ng.
- DÃ¹ng khi storage backend khÃ´ng há»— trá»£ dynamic hoáº·c mÃ´i trÆ°á»ng lab/test.

2. Dynamic Provisioning

- Developer chá»‰ cáº§n táº¡o PVC.
- Cluster sáº½ tá»± Ä‘á»™ng táº¡o PV má»›i phÃ¹ há»£p nhá» StorageClass (SC).
- Äiá»u kiá»‡n:
  - Admin pháº£i cáº¥u hÃ¬nh StorageClass vá»›i má»™t Provisioner plugin (vÃ­ dá»¥: nfs-subdir-external-provisioner, Ceph, EBS, v.v.).
  - Náº¿u default SC chÆ°a Ä‘á»‹nh nghÄ©a, PVC pháº£i chá»‰ rÃµ storageClassName.

3. StorageClass (SC)
- LÃ  â€œprofileâ€ cá»§a storage: Ä‘á»‹nh nghÄ©a loáº¡i storage, tá»‘c Ä‘á»™, reclaim policy,â€¦
- VÃ­ dá»¥ SC:
```
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
reclaimPolicy: Delete
volumeBindingMode: Immediate
```
- provisioner: plugin lo viá»‡c cáº¥p phÃ¡t storage.
- reclaimPolicy: Delete (xoÃ¡ PV khi xoÃ¡ PVC) hoáº·c Retain (giá»¯ láº¡i PV).
- is-default-class: "true" â†’ PVC nÃ o khÃ´ng ghi storageClassName thÃ¬ máº·c Ä‘á»‹nh dÃ¹ng SC nÃ y.

4. PVC vá»›i Dynamic Provisioning

VÃ­ dá»¥:
```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dynamic-volume-claim
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: nfs-storage
```
- Khi táº¡o PVC nÃ y â†’ SC nfs-storage sáº½ táº¡o ra má»™t PV má»›i tá»± Ä‘á»™ng â†’ PVC Ä‘Æ°á»£c bind.
- Admin khÃ´ng cáº§n táº¡o PV thá»§ cÃ´ng.

So sÃ¡nh
| Äáº·c Ä‘iá»ƒm    | Static Provisioning   | Dynamic Provisioning            |
| ----------- | --------------------- | ------------------------------- |
| Ai táº¡o PV   | Admin                 | Tá»± Ä‘á»™ng (qua StorageClass)      |
| Ai táº¡o PVC  | Developer             | Developer                       |
| Linh hoáº¡t   | KÃ©m                   | Cao                             |
| ThÆ°á»ng dÃ¹ng | Test, storage cá»‘ Ä‘á»‹nh | Production, CI/CD, Cloud-native |







